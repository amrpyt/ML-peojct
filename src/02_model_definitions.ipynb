{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definitions\n",
    "\n",
    "This notebook contains the definitions for all required deep learning models:\n",
    "1. 1D Convolutional Neural Network (1DCNN)\n",
    "2. Recurrent Neural Network (RNN)\n",
    "3. Deep Neural Network (DNN)\n",
    "4. Long Short-Term Memory (LSTM)\n",
    "5. Bidirectional LSTM (BiLSTM)\n",
    "6. CNN-LSTM Hybrid\n",
    "7. CNN-BiLSTM Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Flatten, Bidirectional, MaxPooling1D, Dropout\n",
    "\n",
    "# Load preprocessed data to get input shape\n",
    "X_train = np.load('preprocessed/X_train.npy')\n",
    "y_train = np.load('preprocessed/y_train.npy')\n",
    "\n",
    "# Get dimensions\n",
    "num_features = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Input features: {num_features}\")\n",
    "print(f\"Output classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 1D Convolutional Neural Network (1DCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_1dcnn():\n",
    "    model = Sequential([\n",
    "        Conv1D(64, 2, activation='relu', input_shape=(num_features, 1)),\n",
    "        Conv1D(32, 2, activation='relu'),\n",
    "        MaxPooling1D(2),\n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "cnn_model = create_1dcnn()\n",
    "print(\"\\n1DCNN Model Summary:\")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_rnn():\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.SimpleRNN(64, input_shape=(num_features, 1)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "rnn_model = create_rnn()\n",
    "print(\"\\nRNN Model Summary:\")\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep Neural Network (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_dnn():\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(num_features, 1)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "dnn_model = create_dnn()\n",
    "print(\"\\nDNN Model Summary:\")\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_lstm():\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(num_features, 1)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "lstm_model = create_lstm()\n",
    "print(\"\\nLSTM Model Summary:\")\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bidirectional LSTM (BiLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_bilstm():\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(64), input_shape=(num_features, 1)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "bilstm_model = create_bilstm()\n",
    "print(\"\\nBiLSTM Model Summary:\")\n",
    "bilstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CNN-LSTM Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_cnn_lstm():\n",
    "    model = Sequential([\n",
    "        # CNN layers for feature extraction\n",
    "        Conv1D(32, 2, activation='relu', input_shape=(num_features, 1)),\n",
    "        MaxPooling1D(2),\n",
    "        Conv1D(16, 2, activation='relu'),\n",
    "        \n",
    "        # LSTM layer for temporal features\n",
    "        LSTM(32, return_sequences=False),\n",
    "        \n",
    "        # Dense layers for classification\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "cnn_lstm_model = create_cnn_lstm()\n",
    "print(\"\\nCNN-LSTM Model Summary:\")\n",
    "cnn_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. CNN-BiLSTM Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_cnn_bilstm():\n",
    "    model = Sequential([\n",
    "        # CNN layers for feature extraction\n",
    "        Conv1D(32, 2, activation='relu', input_shape=(num_features, 1)),\n",
    "        MaxPooling1D(2),\n",
    "        Conv1D(16, 2, activation='relu'),\n",
    "        \n",
    "        # BiLSTM layer for temporal features\n",
    "        Bidirectional(LSTM(16, return_sequences=False)),\n",
    "        \n",
    "        # Dense layers for classification\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "cnn_bilstm_model = create_cnn_bilstm()\n",
    "print(\"\\nCNN-BiLSTM Model Summary:\")\n",
    "cnn_bilstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "# Create dictionary of model functions\n",
    "model_functions = {\n",
    "    '1DCNN': create_1dcnn,\n",
    "    'RNN': create_rnn,\n",
    "    'DNN': create_dnn,\n",
    "    'LSTM': create_lstm,\n",
    "    'BiLSTM': create_bilstm,\n",
    "    'CNN-LSTM': create_cnn_lstm,\n",
    "    'CNN-BiLSTM': create_cnn_bilstm\n",
    "}\n",
    "\n",
    "# Save functions\n",
    "with open('models/model_functions.pkl', 'wb') as f:\n",
    "    pickle.dump(model_functions, f)\n",
    "\n",
    "print(\"Model functions saved successfully!\")\n",
    "\n",
    "# Print model sizes\n",
    "print(\"\\nModel Parameter Counts:\")\n",
    "for name, create_fn in model_functions.items():\n",
    "    model = create_fn()\n",
    "    print(f\"{name}: {model.count_params():,} parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}