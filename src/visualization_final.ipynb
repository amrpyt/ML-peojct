{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Model Performance Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Classification Models:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nRegression Models:\")\n",
    "print(\"\\nTemperature Prediction:\")\n",
    "for metric, value in metrics['Temperature'].items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nHumidity Prediction:\")\n",
    "for metric, value in metrics['Humidity'].items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot model performance\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(1, 2, 1)\n",
    "accuracies = [result['accuracy'] for result in results.values()]\n",
    "plt.bar(results.keys(), accuracies)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "for i, v in enumerate(accuracies):\n",
    "    plt.text(i, v, f'{v:.3f}', ha='center')\n",
    "\n",
    "# Size comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(['Original', 'Optimized'], [original_size, sizes['Quantized']])\n",
    "plt.title('Model Size Comparison')\n",
    "plt.ylabel('Size (KB)')\n",
    "plt.text(0, original_size, f'{original_size:.1f}KB', ha='center')\n",
    "plt.text(1, sizes['Quantized'], f'{sizes[\"Quantized\"]:.1f}KB', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot regression predictions\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Temperature prediction plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test_temp, temp_pred, alpha=0.5)\n",
    "plt.plot([y_test_temp.min(), y_test_temp.max()],\n",
    "         [y_test_temp.min(), y_test_temp.max()], 'r--')\n",
    "plt.title(f'Temperature Prediction (R² = {metrics[\"Temperature\"][\"R²\"]:.4f})')\n",
    "plt.xlabel('Actual Temperature')\n",
    "plt.ylabel('Predicted Temperature')\n",
    "\n",
    "# Humidity prediction plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test_hum, hum_pred, alpha=0.5)\n",
    "plt.plot([y_test_hum.min(), y_test_hum.max()],\n",
    "         [y_test_hum.min(), y_test_hum.max()], 'r--')\n",
    "plt.title(f'Humidity Prediction (R² = {metrics[\"Humidity\"][\"R²\"]:.4f})')\n",
    "plt.xlabel('Actual Humidity')\n",
    "plt.ylabel('Predicted Humidity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\nFinal Summary\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Best Classification Model: {best_model_name}\")\n",
    "print(f\"Classification Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
    "print(\"\\nModel Size Reduction:\")\n",
    "print(f\"Original: {original_size:.1f} KB\")\n",
    "print(f\"Optimized: {sizes['Quantized']:.1f} KB\")\n",
    "print(f\"Reduction: {((original_size - sizes['Quantized']) / original_size * 100):.1f}%\")\n",
    "\n",
    "print(\"\\nRegression Performance:\")\n",
    "print(f\"Temperature R²: {metrics['Temperature']['R²']:.4f}\")\n",
    "print(f\"Humidity R²: {metrics['Humidity']['R²']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}